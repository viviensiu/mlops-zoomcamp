{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa1432f6",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "The goal of this homework is to create a simple training pipeline, use mlflow to track experiments and register best model, but use Mage for it.\n",
    "\n",
    "We'll use [the same NYC taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page), the **Yellow** taxi data for March, 2023. \n",
    "\n",
    "## Question 1. Select the Tool\n",
    "\n",
    "You can use the same tool you used when completing the module,\n",
    "or choose a different one for your homework.\n",
    "\n",
    "What's the name of the orchestrator you chose? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54952de7",
   "metadata": {},
   "source": [
    "**Answer**: Prefect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c34da35",
   "metadata": {},
   "source": [
    "\n",
    "## Question 2. Version\n",
    "\n",
    "What's the version of the orchestrator? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd19502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prefect\n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41bf02ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 3.4.5\n"
     ]
    }
   ],
   "source": [
    "print(f'Version: {prefect.__version__}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add6e287",
   "metadata": {},
   "source": [
    "## Question 3. Creating a pipeline\n",
    "\n",
    "Let's read the March 2023 Yellow taxi trips data.\n",
    "\n",
    "How many records did we load? \n",
    "\n",
    "- 3,003,766\n",
    "- 3,203,766\n",
    "- 3,403,766\n",
    "- 3,603,766\n",
    "\n",
    "(Include a print statement in your code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0278ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet'\n",
    "df = pd.read_parquet(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ce7e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 3403766\n"
     ]
    }
   ],
   "source": [
    "print(f'Answer: {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4732d018",
   "metadata": {},
   "source": [
    "## Question 4. Data preparation\n",
    "\n",
    "Let's continue with pipeline creation.\n",
    "\n",
    "We will use the same logic for preparing the data we used previously. \n",
    "\n",
    "This is what we used (adjusted for yellow dataset):\n",
    "\n",
    "```python\n",
    "def read_dataframe(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df\n",
    "```\n",
    "\n",
    "Let's apply to the data we loaded in question 3. \n",
    "\n",
    "What's the size of the result? \n",
    "\n",
    "- 2,903,766\n",
    "- 3,103,766\n",
    "- 3,316,216 \n",
    "- 3,503,766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c23a251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66bf58cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 3316216\n"
     ]
    }
   ],
   "source": [
    "df = read_dataframe(file)\n",
    "print(f'Answer: {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3add8966",
   "metadata": {},
   "source": [
    "## Question 5. Train a model\n",
    "\n",
    "We will now train a linear regression model using the same code as in homework 1.\n",
    "\n",
    "* Fit a dict vectorizer.\n",
    "* Train a linear regression with default parameters.\n",
    "* Use pick up and drop off locations separately, don't create a combination feature.\n",
    "\n",
    "Let's now use it in the pipeline. We will need to create another transformation block, and return both the dict vectorizer and the model.\n",
    "\n",
    "What's the intercept of the model? \n",
    "\n",
    "Hint: print the `intercept_` field in the code block\n",
    "\n",
    "- 21.77\n",
    "- 24.77\n",
    "- 27.77\n",
    "- 31.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b805d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe(df):\n",
    "    # Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will \n",
    "    # label encode them)\n",
    "    id_list = ['DOLocationID', 'PULocationID']\n",
    "    df = df[id_list].astype(str)\n",
    "    dict_df = df.to_dict(orient='records')\n",
    "    \n",
    "    return dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8417e92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60ce3432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 10:06:03 INFO mlflow.tracking.fluent: Experiment with name 'linreg' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"linreg\")\n",
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5eb65d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run capricious-crow-89 at: http://127.0.0.1:5000/#/experiments/1/runs/b80cd7bbe1fe4c1d82d2dd69d67593c8\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    # Fit a dictionary vectorizer\n",
    "    # Get a feature matrix from it\n",
    "    dv = DictVectorizer()\n",
    "    dict_df = ohe(df)\n",
    "    X_train = dv.fit_transform(dict_df)\n",
    "    y_train = df['duration'].values\n",
    "    model = train_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aec8983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 24.78\n"
     ]
    }
   ],
   "source": [
    "print(f'Intercept: {model.intercept_:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741fb0b3",
   "metadata": {},
   "source": [
    "## Question 6. Register the model \n",
    "\n",
    "The model is trained, so let's save it with MLFlow.\n",
    "\n",
    "Find the logged model, and find MLModel file. What's the size of the model? (`model_size_bytes` field):\n",
    "\n",
    "* 14,534\n",
    "* 9,534\n",
    "* 4,534\n",
    "* 1,534\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89ad2b6",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "* Include codes\n",
    "    ```python\n",
    "    import mlflow\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "    mlflow.set_experiment(\"linreg\")\n",
    "    mlflow.sklearn.autolog()\n",
    "    .\n",
    "    .\n",
    "    with mlflow.start_run():\n",
    "        # model training\n",
    "    ```\n",
    "* start mlflow server\n",
    "    ```bash\n",
    "    mlflow server --backend-store-uri sqlite:///unit3_homework.db --default-artifact-root ./artifacts\n",
    "    ```\n",
    "* open mlflow ui\n",
    "* run notebook, make sure everything completed without errors.\n",
    "* check mlflow ui > `experiment` is `linreg` > click on the run under `linreg` > click on `artifacts` tab > `model > MLmodel` > refer `model_size_bytes` > `4501`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df80bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd60e168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5d4db11",
   "metadata": {},
   "source": [
    "## Submit the results\n",
    "\n",
    "* Submit your results here: https://courses.datatalks.club/mlops-zoomcamp-2025/homework/hw3\n",
    "* If your answer doesn't match options exactly, select the closest one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp-tracking-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
